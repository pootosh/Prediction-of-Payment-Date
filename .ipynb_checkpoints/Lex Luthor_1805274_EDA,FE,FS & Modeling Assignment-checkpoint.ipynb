{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"1805274.csv\")\n",
    "df.info()           # printing top 5 rows of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of null values in columns\n",
    "\n",
    "df.isnull().sum()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping column which contains only null values in columns\n",
    "\n",
    "df.drop(columns = [\"area_business\"], inplace = True)   \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe whose all rows in clear_date column is null\n",
    "\n",
    "df1 = df[df[\"clear_date\"].isnull()]\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe whose rows in clear_date column is not null\n",
    "\n",
    "df2 = df[df[\"clear_date\"].isnull() != True]\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating another dataframe and storing the data after dropping the row which have any null column because only four columns \n",
    "# have null values\n",
    "\n",
    "df3 = df2.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graphs to detect outliers\n",
    "\n",
    "plt.boxplot(x=df3[\"total_open_amount\"])\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df3[\"business_code\"], df3[\"total_open_amount\"])\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum and maximum of df3[\"total_open_amount\"]\n",
    "\n",
    "min(df3[\"total_open_amount\"]), max(df3[\"total_open_amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum total_open_amount w.r.t to their business_code\n",
    "\n",
    "df3.groupby(\"business_code\")[\"total_open_amount\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data present in rows w.r.t \"business_code\"\n",
    "\n",
    "df3.groupby(\"business_code\")[\"business_code\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking business_code CA02 max value as outlier upper limit counting outliers\n",
    "\n",
    "df3[df3[\"total_open_amount\"] > 487872.00].groupby(\"business_code\")[\"business_code\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping outliers because only 4 data are outlier according to my upper limit and their are many more data in U001\n",
    "\n",
    "index_no = df3[df3[\"total_open_amount\"] > 487872.00].index\n",
    "df3.drop(index_no, inplace= True)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now difference between consecutive points are less in this graph\n",
    "\n",
    "plt.scatter(df3[\"business_code\"], df3[\"total_open_amount\"])\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df3[\"total_open_amount\"])\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log(df3[\"total_open_amount\"])\n",
    "plt.hist(y)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[\"total_open_amount\"] = np.log(df3[\"total_open_amount\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.groupby(\"business_code\")[\"total_open_amount\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resetting index\n",
    "df1.reset_index(inplace = True, drop = True)\n",
    "df2.reset_index(inplace = True, drop = True)\n",
    "df3.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting dataframe on the basis of document_create_date.1\n",
    "\n",
    "df3.sort_values([\"document_create_date.1\"], inplace = True)\n",
    "df3.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# converting date columns in date time format\n",
    "\n",
    "df3[\"document_create_date.1\"] = pd.to_datetime(df3[\"document_create_date.1\"].astype(str), format='%Y%m%d')\n",
    "df3[\"baseline_create_date\"] = pd.to_datetime(df3[\"baseline_create_date\"].astype(str), format = '%Y%m%d')\n",
    "df3[\"due_in_date\"] = pd.to_datetime(df3[\"due_in_date\"].astype(str), format = '%Y%m%d')\n",
    "df3[\"posting_date\"] = pd.to_datetime(df3[\"posting_date\"])\n",
    "df3[\"clear_date\"] = pd.to_datetime(df3[\"clear_date\"])\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping column which have only one unique value\n",
    "\n",
    "df3.drop(columns = [\"document type\", \"posting_id\", \"isOpen\"], inplace = True)\n",
    "df3.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping document_create_date because we have to use document_create_date.1\n",
    "\n",
    "df3.drop(columns = [\"document_create_date\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming document_create_date.1 into create_date\n",
    "\n",
    "df3.rename(columns = {\"document_create_date.1\": \"create_date\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data on the basis of date\n",
    "\n",
    "X_train = df3[df3[\"create_date\"] <= '2019-09-30'].copy()\n",
    "X_temp = df3[df3[\"create_date\"] > '2019-09-30'].copy()\n",
    "\n",
    "X_validation = X_temp[X_temp[\"create_date\"] <= '2019-11-15'].copy()\n",
    "X_test = X_temp[X_temp[\"create_date\"] > '2019-11-15'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting index\n",
    "\n",
    "X_train.reset_index(drop = True, inplace = True)\n",
    "X_validation.reset_index(drop = True, inplace = True)\n",
    "X_test.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of data after splitting \n",
    "\n",
    "X_train.shape, X_validation.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysing baseline_create_date and posting_date is similar to create_date or not\n",
    "\n",
    "diff_crdate_bcrdate = (X_train[\"create_date\"] - X_train[\"baseline_create_date\"]).dt.days\n",
    "diff_crdate_posdate = (X_train[\"create_date\"] - X_train[\"posting_date\"]).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(diff_crdate_posdate)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(diff_crdate_bcrdate)\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping posting date\n",
    "\n",
    "X_train.drop(columns = [\"posting_date\"], inplace = True)       #train\n",
    "X_validation.drop(columns = [\"posting_date\"], inplace = True)      #validation\n",
    "X_test.drop(columns = [\"posting_date\"], inplace = True)           #test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#difference between due_date and clear_date\n",
    "# clear_date >= due_in_date >= create_date >=< baseline_create_date >= posting_date\n",
    "\n",
    "#train\n",
    "X_train[\"diff_duedate_crdate\"] = (X_train[\"due_in_date\"]-X_train[\"create_date\"]).dt.days\n",
    "X_train[\"diff_crdate_bcrdate\"] = (X_train[\"create_date\"] - X_train[\"baseline_create_date\"]).dt.days\n",
    "X_train[\"diff_cldate_duedate\"] = (X_train[\"clear_date\"] - X_train[\"due_in_date\"]).dt.days  # target column\n",
    "\n",
    "#validation\n",
    "X_validation[\"diff_duedate_crdate\"] = (X_validation[\"due_in_date\"] - X_validation[\"create_date\"]).dt.days\n",
    "X_validation[\"diff_crdate_bcrdate\"] = (X_validation[\"create_date\"] - X_validation[\"baseline_create_date\"]).dt.days\n",
    "X_validation[\"diff_cldate_duedate\"] = (X_validation[\"clear_date\"] - X_validation[\"due_in_date\"]).dt.days\n",
    "\n",
    "#test\n",
    "X_test[\"diff_duedate_crdate\"] = (X_test[\"due_in_date\"] - X_test[\"create_date\"]).dt.days\n",
    "X_test[\"diff_crdate_bcrdate\"] = (X_test[\"create_date\"] - X_test[\"baseline_create_date\"]).dt.days\n",
    "X_test[\"diff_cldate_duedate\"] = (X_test[\"clear_date\"] - X_test[\"due_in_date\"]).dt.days\n",
    "\n",
    "#X_train[\"diff_cldate_crdate\"] = (X_train[\"clear_date\"] - X_train[\"create_date\"]).dt.days\n",
    "#X_train[\"diff_crdate_bcrdate\"] = (X_train[\"create_date\"] - X_train[\"baseline_create_date\"]).dt.days\n",
    "#X_train[\"diff_cldate_pdate\"] = (X_train[\"create_date\"] - X_train[\"posting_date\"]).dt.days\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping those column whose due_date is less than create date\n",
    "\n",
    "index_no_train = X_train[X_train[\"diff_cldate_duedate\"]<0].index\n",
    "X_train.drop(index_no_train, inplace= True)\n",
    "\n",
    "index_no_validation = X_validation[X_validation[\"diff_cldate_duedate\"]<0].index\n",
    "X_validation.drop(index_no_validation, inplace= True)\n",
    "\n",
    "index_no_test = X_test[X_test[\"diff_cldate_duedate\"]<0].index\n",
    "X_test.drop(index_no_test, inplace= True)\n",
    "\n",
    "#resetting index\n",
    "\n",
    "X_train.reset_index(drop = True, inplace = True)\n",
    "X_validation.reset_index(drop = True, inplace = True)\n",
    "X_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping doc_id and invoice_id \n",
    "X_train.drop(columns = [\"doc_id\", \"invoice_id\"], inplace = True)\n",
    "X_validation.drop(columns = [\"doc_id\", \"invoice_id\"], inplace = True)\n",
    "X_test.drop(columns = [\"doc_id\", \"invoice_id\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting month, year, day of week from data\n",
    "\n",
    "#create_date\n",
    "X_train[\"cr_day\"] = X_train[\"create_date\"].dt.dayofweek                    #train\n",
    "X_train[\"cr_month\"] = X_train[\"create_date\"].dt.month\n",
    "X_train[\"cr_year\"] = X_train[\"create_date\"].dt.year\n",
    "\n",
    "X_validation[\"cr_day\"] = X_validation[\"create_date\"].dt.dayofweek          #validation\n",
    "X_validation[\"cr_month\"] = X_validation[\"create_date\"].dt.month\n",
    "X_validation[\"cr_year\"] = X_validation[\"create_date\"].dt.year\n",
    "\n",
    "X_test[\"cr_day\"] = X_test[\"create_date\"].dt.dayofweek                      #test\n",
    "X_test[\"cr_month\"] = X_test[\"create_date\"].dt.month\n",
    "X_test[\"cr_year\"] = X_test[\"create_date\"].dt.year\n",
    "\n",
    "#due_in_date\n",
    "X_train[\"due_day\"] = X_train[\"due_in_date\"].dt.dayofweek                   #train\n",
    "X_train[\"due_month\"] = X_train[\"due_in_date\"].dt.month\n",
    "X_train[\"due_year\"] = X_train[\"due_in_date\"].dt.year\n",
    "\n",
    "X_validation[\"due_day\"] = X_validation[\"due_in_date\"].dt.dayofweek         #validation\n",
    "X_validation[\"due_month\"] = X_validation[\"due_in_date\"].dt.month\n",
    "X_validation[\"due_year\"] = X_validation[\"due_in_date\"].dt.year\n",
    "\n",
    "X_test[\"due_day\"] = X_test[\"due_in_date\"].dt.dayofweek                     #test\n",
    "X_test[\"due_month\"] = X_test[\"due_in_date\"].dt.month\n",
    "X_test[\"due_year\"] = X_test[\"due_in_date\"].dt.year\n",
    "\n",
    "\"\"\"#clear_date\n",
    "X_train[\"cl_month\"] = X_train[\"clear_date\"].dt.month                       #train\n",
    "X_train[\"cl_year\"] = X_train[\"clear_date\"].dt.year\n",
    "X_train[\"cl_day\"] = X_train[\"clear_date\"].dt.dayofweek\n",
    "\n",
    "X_validation[\"cl_month\"] = X_validation[\"clear_date\"].dt.month             #validation\n",
    "X_validation[\"cl_year\"] = X_validation[\"clear_date\"].dt.year\n",
    "X_validation[\"cl_day\"] = X_validation[\"clear_date\"].dt.dayofweek\n",
    "\n",
    "X_test[\"cl_month\"] = X_test[\"clear_date\"].dt.month                         #test\n",
    "X_test[\"cl_year\"] = X_test[\"clear_date\"].dt.year\n",
    "X_test[\"cl_day\"] = X_test[\"clear_date\"].dt.dayofweek\n",
    "\n",
    "#baseline_create_date\n",
    "X_train[\"bcr_month\"] = X_train[\"baseline_create_date\"].dt.month                       #train\n",
    "X_train[\"bcr_year\"] = X_train[\"baseline_create_date\"].dt.year\n",
    "X_train[\"bcr_day\"] = X_train[\"baseline_create_date\"].dt.dayofweek\n",
    "\n",
    "X_validation[\"bcr_month\"] = X_validation[\"baseline_create_date\"].dt.month                       #validation\n",
    "X_validation[\"bcr_year\"] = X_validation[\"baseline_create_date\"].dt.year\n",
    "X_validation[\"bcr_day\"] = X_validation[\"baseline_create_date\"].dt.dayofweek\n",
    "\n",
    "X_test[\"bcr_month\"] = X_test[\"baseline_create_date\"].dt.month                       #test\n",
    "X_test[\"bcr_year\"] = X_test[\"baseline_create_date\"].dt.year\n",
    "X_test[\"bcr_day\"] = X_test[\"baseline_create_date\"].dt.dayofweek\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping datetime data type columns \n",
    "\n",
    "X_train.drop(columns = [\"baseline_create_date\", \"clear_date\", \"create_date\", \"due_in_date\"], inplace = True)\n",
    "X_validation.drop(columns = [\"baseline_create_date\", \"clear_date\", \"create_date\", \"due_in_date\"], inplace = True)\n",
    "X_test.drop(columns = [\"baseline_create_date\", \"clear_date\", \"create_date\", \"due_in_date\"], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"invoice_currency\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping invoice currency in 1 and 0 because only two unique values in invoice_currency\n",
    "\n",
    "X_train[\"invoice_currency\"] = X_train[\"invoice_currency\"].map({'USD' : 1, 'CAD' : 0})\n",
    "X_validation[\"invoice_currency\"] = X_validation[\"invoice_currency\"].map({'USD' : 1, 'CAD' : 0})\n",
    "X_test[\"invoice_currency\"] = X_test[\"invoice_currency\"].map({'USD' : 1, 'CAD' : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rare label encoding of business_code\n",
    "# change the rare category names with the word others, and thus encoding it.\n",
    "threshlold = 0.05\n",
    "\n",
    "                                   #train\n",
    "counts_train = X_train.groupby([\"business_code\"])[\"business_code\"].count() / len(X_train)\n",
    "frequent_labels_train = [x for x in counts_train.loc[counts_train > threshlold].index.values]\n",
    "\n",
    "X_train[\"business_code\"] = np.where(X_train[\"business_code\"].isin(frequent_labels_train), X_train[\"business_code\"], 'Others')\n",
    "X_train[\"business_code\"] = np.where(X_train[\"business_code\"].isin(frequent_labels_train), X_train[\"business_code\"], 'Others')\n",
    "\n",
    "                                #validation\n",
    "counts_validation = X_validation.groupby([\"business_code\"])[\"business_code\"].count() / len(X_validation)\n",
    "frequent_labels_validation = [x for x in counts_validation.loc[counts_validation > threshlold].index.values]\n",
    "\n",
    "X_validation[\"business_code\"] = np.where(X_validation[\"business_code\"].isin(frequent_labels_validation), X_validation[\"business_code\"], 'Others')\n",
    "X_validation[\"business_code\"] = np.where(X_validation[\"business_code\"].isin(frequent_labels_validation), X_validation[\"business_code\"], 'Others')\n",
    "\n",
    "                                   #test\n",
    "counts_test = X_test.groupby([\"business_code\"])[\"business_code\"].count() / len(X_test)\n",
    "frequent_labels_test = [x for x in counts_test.loc[counts_test > threshlold].index.values]\n",
    "\n",
    "X_test[\"business_code\"] = np.where(X_test[\"business_code\"].isin(frequent_labels_test), X_test[\"business_code\"], 'Others')\n",
    "X_test[\"business_code\"] = np.where(X_test[\"business_code\"].isin(frequent_labels_test), X_test[\"business_code\"], 'Others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"business_code\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping business_code\n",
    "\n",
    "X_train[\"business_code\"] = X_train[\"business_code\"].map({\"U001\" : 1, \"CA02\" : 2, \"Others\" : 3})\n",
    "X_validation[\"business_code\"] = X_validation[\"business_code\"].map({\"U001\" : 1, \"CA02\" : 2, \"Others\" : 3})\n",
    "X_test[\"business_code\"] = X_test[\"business_code\"].map({\"U001\" : 1, \"CA02\" : 2, \"Others\" : 3})\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rare_label(column, threshold):\n",
    "    counts_train = X_train.groupby([column])[column].count() / len(X_train)\n",
    "    frequent_labels_train = [x for x in counts_train.loc[counts_train > threshlold].index.values]\n",
    "\n",
    "    X_train[column] = np.where(X_train[column].isin(frequent_labels_train), X_train[column], 'Others')\n",
    "    X_train[column] = np.where(X_train[column].isin(frequent_labels_train), X_train[column], 'Others')\n",
    "\n",
    "                                    #validation\n",
    "    counts_validation = X_validation.groupby([column])[column].count() / len(X_validation)\n",
    "    frequent_labels_validation = [x for x in counts_validation.loc[counts_validation > threshlold].index.values]\n",
    "\n",
    "    X_validation[column] = np.where(X_validation[column].isin(frequent_labels_validation), X_validation[column], 'Others')\n",
    "    X_validation[column] = np.where(X_validation[column].isin(frequent_labels_validation), X_validation[column], 'Others')\n",
    "\n",
    "                                       #test\n",
    "    counts_test = X_test.groupby([column])[column].count() / len(X_test)\n",
    "    frequent_labels_test = [x for x in counts_test.loc[counts_test > threshlold].index.values]\n",
    "\n",
    "    X_test[column] = np.where(X_test[column].isin(frequent_labels_test), X_test[column], 'Others')\n",
    "    X_test[column] = np.where(X_test[column].isin(frequent_labels_test), X_test[column], 'Others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First name of the name_customer\n",
    "\n",
    "X_train[\"name_customer\"]= X_train.name_customer.str.split(' ').str[0]\n",
    "X_validation[\"name_customer\"]= X_validation.name_customer.str.split(' ').str[0]\n",
    "X_test[\"name_customer\"]= X_test.name_customer.str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"name_customer\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First four digit of cust_number\n",
    "X_train[\"cust_number\"] = X_train.cust_number.str[:4]\n",
    "X_validation[\"cust_number\"] = X_validation.cust_number.str[:4]\n",
    "X_test[\"cust_number\"] = X_test.cust_number.str[:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"cust_number\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"cust_number\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_label(\"cust_number\", 0.05)\n",
    "X_train[\"cust_number\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"cust_number\"] = X_train[\"cust_number\"].map({'0200' : 1, '0140' : 2, 'Others' : 3, '2007' : 4})\n",
    "X_validation[\"cust_number\"] = X_validation[\"cust_number\"].map({'0200' : 1, '0140' : 2, 'Others' : 3, '2007' : 4})\n",
    "X_test[\"cust_number\"] = X_test[\"cust_number\"].map({'0200' : 1, '0140' : 2, 'Others' : 3, '2007' : 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_label(\"name_customer\", 0.05)\n",
    "X_train[\"name_customer\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"name_customer\"] = X_train[\"name_customer\"].map({\"BJ'S\" : 1, 'Others': 2, 'WAL-MAR' : 3})\n",
    "X_validation[\"name_customer\"] = X_validation[\"name_customer\"].map({\"BJ'S\" : 1, 'Others': 2, 'WAL-MAR' : 3})\n",
    "X_test[\"name_customer\"] = X_test[\"name_customer\"].map({\"BJ'S\" : 1, 'Others': 2, 'WAL-MAR' : 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rare_label(\"cust_payment_terms\", 0.005)\n",
    "X_train[\"cust_payment_terms\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"cust_payment_terms\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"cust_payment_terms\"] = X_train[\"cust_payment_terms\"].map({'NAA8' : 1, 'Others' : 2, 'NAH4' : 3, 'CA10' : 4})\n",
    "X_validation[\"cust_payment_terms\"] = X_validation[\"cust_payment_terms\"].map({'NAA8' : 1, 'Others' : 2, 'NAH4' : 3, 'CA10' : 4})\n",
    "X_test[\"cust_payment_terms\"] = X_test[\"cust_payment_terms\"].map({'NAA8' : 1, 'Others' : 2, 'NAH4' : 3, 'CA10' : 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(columns = [\"buisness_year\"], inplace = True)\n",
    "X_validation.drop(columns = [\"buisness_year\"], inplace = True)\n",
    "X_test.drop(columns = [\"buisness_year\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(X_train.corr(), annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = X_train[\"diff_cldate_duedate\"]\n",
    "X_train = X_train.drop(columns = [\"diff_cldate_duedate\"])\n",
    "\n",
    "Y_validation = X_validation[\"diff_cldate_duedate\"]\n",
    "X_validation = X_validation.drop(columns = [\"diff_cldate_duedate\"])\n",
    "\n",
    "Y_test = X_test[\"diff_cldate_duedate\"]\n",
    "X_test = X_test.drop(columns = [\"diff_cldate_duedate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X_train.columns:\n",
    "    print(i,Y_train.corr(X_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst =[]\n",
    "for i in X_train.columns:\n",
    "    lst.append(i)\n",
    "lst.remove(\"name_customer\")\n",
    "lst.remove(\"cust_payment_terms\")\n",
    "lst.remove(\"diff_crdate_bcrdate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = lst#['business_code', 'cust_number', 'invoice_currency', 'diff_duedate_crdate', 'cr_month', 'due_day', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Simple Linear Regression to the Training Set\n",
    "Algorithm.append('Linear Regression')\n",
    "clf.fit(X_train[features], Y_train)\n",
    "\n",
    "# Predicting the Test Set Results\n",
    "#predicted_validation = clf.predict(X_validation[features])\n",
    "predicted_train = clf.predict(X_train[features])\n",
    "#predicted_test = clf.predict(X_test[features])\n",
    "\n",
    "# Appending the Scores For Visualisation at a Later Part\n",
    "mean_squared_error(Y_train, predicted_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting SVR to the Training Set\n",
    "Algorithm.append('Support Vector Regression')\n",
    "clf = SVR()\n",
    "clf.fit(X_train[features], Y_train)\n",
    "\n",
    "# Predicting the Test Set Results\n",
    "predicted_validation = clf.predict(X_validation[features])\n",
    "predicted_train = clf.predict(X_train[features])\n",
    "predicted_test = clf.predict(X_test[features])\n",
    "\n",
    "# Appending the Scores For Visualisation at a Later Part\n",
    "mean_squared_error(Y_validation, predicted_validation), mean_squared_error(Y_train, predicted_train), mean_squared_error(Y_test, predicted_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree RegressorÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Decision Tree to the Training Set\n",
    "Algorithm.append('Decision Tree Regressor')\n",
    "clf = DecisionTreeRegressor()\n",
    "clf.fit(X_train[features], Y_train)\n",
    "\n",
    "# Predicting the Test Set Results\n",
    "predicted_validation = clf.predict(X_validation[features])\n",
    "predicted_train = clf.predict(X_train[features])\n",
    "predicted_test = clf.predict(X_test[features])\n",
    "\n",
    "# Appending the Scores For Visualisation at a Later Part\n",
    "mean_squared_error(Y_validation, predicted_validation), mean_squared_error(Y_train, predicted_train), mean_squared_error(Y_test, predicted_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest Regressor Tree to the Training Set\n",
    "Algorithm.append('Random Forest Regressor')\n",
    "clf = RandomForestRegressor()\n",
    "clf.fit(X_train[features], Y_train)\n",
    "\n",
    "# Predicting the Test Set Results\n",
    "predicted_validation = clf.predict(X_validation[features])\n",
    "predicted_train = clf.predict(X_train[features])\n",
    "predicted_test = clf.predict(X_test[features])\n",
    "\n",
    "# Appending the Scores For Visualisation at a Later Part\n",
    "mean_squared_error(Y_validation, predicted_validation), mean_squared_error(Y_train, predicted_train), mean_squared_error(Y_test, predicted_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting XGBoost Regressor to the Training Set\n",
    "Algorithm.append('XGB Regressor')\n",
    "clf = xgb.XGBRegressor()\n",
    "clf.fit(X_train[features], Y_train)\n",
    "\n",
    "# Predicting the Test Set Results\n",
    "predicted_validation = clf.predict(X_validation[features])\n",
    "predicted_train = clf.predict(X_train[features])\n",
    "predicted_test = clf.predict(X_test[features])\n",
    "\n",
    "# Appending the Scores For Visualisation at a Later Part\n",
    "mean_squared_error(Y_validation, predicted_validation), mean_squared_error(Y_train, predicted_train), mean_squared_error(Y_test, predicted_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
